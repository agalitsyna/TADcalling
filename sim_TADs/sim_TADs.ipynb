{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "import lavaburst\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import tadtool.tad as tad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set initial properties for data location\n",
    "res = 40000\n",
    "data_location = \"matrices/\"\n",
    "armatus_location = \"./armatus\"\n",
    "out_location = \"yielded/\"\n",
    "ins_score_data = data_location + \"ins_score_input/\"\n",
    "noise_values = [4, 8, 12, 16, 20]\n",
    "sim_values = list(range(1, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "armatus_gamma = [i / 10 for i in range(-5, 6)]\n",
    "modularity_gamma = list(range(101))\n",
    "potts_gamma = list(range(41))\n",
    "variance_gamma = list(range(101))\n",
    "corner_gamma = [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.sim=5 gamma=0.51\n"
     ]
    }
   ],
   "source": [
    "# run armatus with all gamma values\n",
    "for noise in noise_values:\n",
    "    for sim in sim_values:\n",
    "        for gamma in armatus_gamma:\n",
    "            print(f\"\\rnoise={noise} sim={sim} gamma={gamma}\", end=\"\")\n",
    "            subprocess.run(f\"bash -c '{armatus_location} -i {data_location}simHiC_countMatrix_noise{noise}_sim{sim}.txt.gz -g {gamma} -j -o {out_location}armatus_gamma{gamma}_noise{noise}_sim{sim} -r {res}'\")\n",
    "print(\"\\rFinished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert armatus tad coordinates for further handling\n",
    "custom_range = [i / 2 for i in range(13)]\n",
    "for gamma in armatus_gamma:\n",
    "    tads = pd.read_csv(f\"{out_location}armatus_gamma{gamma}_noise{noise}_sim{sim}.txt\", comment = \"#\", sep = \"\\t\", header=None)\n",
    "    del tads[0]\n",
    "    tads[2] = tads[2] + 1\n",
    "    tads.to_csv(f\"{out_location}armatus_gamma{gamma}_noise{noise}_sim{sim}.txt\", sep=\"\\t\", header=None, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " finished sim=5\n"
     ]
    }
   ],
   "source": [
    "#load matrices for lavaburst\n",
    "matrices = pd.DataFrame(index=noise_values, columns=sim_values)\n",
    "good_bins = pd.DataFrame(index=noise_values, columns=sim_values)\n",
    "for noise in noise_values:\n",
    "    for sim in sim_values:\n",
    "        print(f\"\\r noise={noise} sim={sim}\", end=\"\")\n",
    "        matrices.loc[noise, sim] = np.loadtxt(f\"{data_location}simHiC_countMatrix_noise{noise}_sim{sim}.txt\")\n",
    "        good_bins.loc[noise, sim] = matrices.loc[noise, sim].astype(bool).sum(axis=0) > 100\n",
    "print(\"\\r finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " noise=20 sim=5 gamma=100 in progress"
     ]
    }
   ],
   "source": [
    "# run lavaburst with modularity score\n",
    "for noise in noise_values:\n",
    "    for sim in sim_values:\n",
    "        for gamma in modularity_gamma:\n",
    "            print(f\"\\r noise={noise} sim={sim} gamma={gamma} in progress\", end=\"\")\n",
    "            S = lavaburst.scoring.modularity_score(matrices.loc[noise, sim], gamma=gamma, binmask=good_bins.loc[noise, sim])\n",
    "            model = lavaburst.SegModel(S)\n",
    "            segments = model.optimal_segmentation()\n",
    "            np.savetxt(f\"{out_location}lava_modularity_noise{noise}_sim{sim}_gamma{gamma}.txt\", segments * res, delimiter=\"\\t\", fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.sim=5 gamma=0.5 in progresss\n"
     ]
    }
   ],
   "source": [
    "#run lavaburst with armatus\n",
    "for noise in noise_values:\n",
    "    for sim in sim_values:\n",
    "        for gamma in armatus_gamma:\n",
    "            print(f\"\\rnoise={noise} sim={sim} gamma={gamma} in progress\", end=\"\")\n",
    "            S = lavaburst.scoring.armatus_score(matrices.loc[noise, sim], gamma=gamma, binmask=good_bins.loc[noise, sim])\n",
    "            model = lavaburst.SegModel(S)\n",
    "            segments = model.optimal_segmentation()\n",
    "            np.savetxt(f\"{out_location}lava_armatus_noise{noise}_sim{sim}_gamma{gamma}.txt\", segments * res, delimiter=\"\\t\", fmt=\"%d\")\n",
    "print(\"\\rFinished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.sim=5 gamma=40 in progress\n"
     ]
    }
   ],
   "source": [
    "#run lavaburst with potts score\n",
    "for noise in noise_values:\n",
    "    for sim in sim_values:\n",
    "        for gamma in potts_gamma:\n",
    "            print(f\"\\rnoise={noise} sim={sim} gamma={gamma} in progress\", end=\"\")\n",
    "            S = lavaburst.scoring.potts_score(matrices.loc[noise, sim], gamma=gamma, binmask=good_bins.loc[noise, sim])\n",
    "            model = lavaburst.SegModel(S)\n",
    "            segments = model.optimal_segmentation()\n",
    "            np.savetxt(f\"{out_location}lava_potts_noise{noise}_sim{sim}_gamma{gamma}.txt\", segments * res, delimiter=\"\\t\", fmt=\"%d\")\n",
    "print(\"\\rFinished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run lavaburst with variance score\n",
    "for noise in noise_values:\n",
    "    for sim in sim_values:\n",
    "        for gamma in variance_gamma:\n",
    "            print(f\"\\r noise={noise} sim={sim} gamma={gamma} in progress\", end=\"\")\n",
    "            S = lavaburst.scoring.variance_score(matrices.loc[noise, sim], gamma=gamma, binmask=good_bins.loc[noise, sim])\n",
    "            model = lavaburst.SegModel(S)\n",
    "            segments = model.optimal_segmentation()\n",
    "            np.savetxt(f\"{out_location}lava_variance_noise{noise}_sim{sim}_gamma{gamma}.txt\", segments * res, delimiter=\"\\t\", fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " noise=20 sim=5 gamma=2 in progress"
     ]
    }
   ],
   "source": [
    "# run lavaburst with corner score\n",
    "for noise in noise_values:\n",
    "    for sim in sim_values:\n",
    "        for gamma in corner_gamma:\n",
    "            print(f\"\\r noise={noise} sim={sim} gamma={gamma} in progress\", end=\"\")\n",
    "            S = lavaburst.scoring.corner_score(matrices.loc[noise, sim], gamma=gamma, binmask=good_bins.loc[noise, sim])\n",
    "            model = lavaburst.SegModel(S)\n",
    "            segments = model.optimal_segmentation()\n",
    "            np.savetxt(f\"{out_location}lava_corner_noise{noise}_sim{sim}_gamma{gamma}.txt\", segments * res, delimiter=\"\\t\", fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert matrices for insulation score DEPRECATED\n",
    "for noise in noise_values:\n",
    "    for sim in sim_values:\n",
    "        ndim = matrices.loc[noise, sim].shape[0]\n",
    "        bin_names = [f\"bin{bin}|sim{sim}noise{noise}|chr1:{bin * res}-{bin * res +res}\" for bin in range(ndim)]\n",
    "        ins_score_matrix = np.empty(shape=(ndim + 1, ndim + 1), dtype=\"object\")\n",
    "        ins_score_matrix[1:, 1:] = matrices.loc[noise, sim]\n",
    "        ins_score_matrix[0, 1:] = bin_names\n",
    "        ins_score_matrix[1:, 0] = bin_names\n",
    "        ins_score_matrix[0,0] = \"\"\n",
    "        np.savetxt(f\"{ins_score_data}simHiC_countMatrix_noise{noise}_sim{sim}.txt\", ins_score_matrix, delimiter=\"\\t\", fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make region bed files for tadtool\n",
    "for noise in noise_values:\n",
    "    for sim in sim_values:\n",
    "        ndim = matrices.loc[noise, sim].shape[0]\n",
    "        regions = np.empty(shape=(ndim, 3), dtype=\"object\")\n",
    "        regions[:, 0] = \"chr1\"\n",
    "        starts = np.array([i * res for i in range(ndim)], dtype=\"int\")\n",
    "        regions[:, 1] = starts\n",
    "        regions[:, 2] = starts + res\n",
    "        np.savetxt(f\"{data_location}region_noise{noise}_sim{sim}.txt\", regions, delimiter=\"\\t\", fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " noise=20 sim=5"
     ]
    }
   ],
   "source": [
    "# load region files for tadtool\n",
    "regions = pd.DataFrame(index=noise_values, columns=sim_values)\n",
    "for noise in noise_values:\n",
    "    for sim in sim_values:\n",
    "        print(f\"\\r noise={noise} sim={sim}\", end=\"\")\n",
    "        regions.loc[noise, sim], some_ix = tad.load_regions(f\"{data_location}region_noise{noise}_sim{sim}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set ranges of values for tadtool\n",
    "cutoff_values = list(range(11))\n",
    "window_values = [res * i for i in list(np.arange(0.5, 5, 0.5))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " window=180000.0 cutoff=10"
     ]
    }
   ],
   "source": [
    "# run tadtool with insulation score\n",
    "for cutoff in cutoff_values:\n",
    "    for window in window_values:\n",
    "        for noise in noise_values:\n",
    "            for sim in sim_values:\n",
    "                print(f\"\\r noise={noise} sim={sim} window={window} cutoff={cutoff}\", end=\"\")\n",
    "                ii = tad.insulation_index(matrices.loc[noise, sim], regions.loc[noise, sim], window_size=window)\n",
    "                tads = tad.call_tads_insulation_index(ii, cutoff, regions=regions.loc[noise, sim])\n",
    "                with open(f\"{out_location}ii_noise{noise}_sim{sim}_window{window}_cutoff{cutoff}.txt\", \"w\") as outfile:\n",
    "                    for some_tad in tads:\n",
    "                        outfile.write(f\"{some_tad.start - 1}\\t{some_tad.end}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " sim=5 noise=20 window=160000 cutoff=15"
     ]
    }
   ],
   "source": [
    "# run tadtool with directionality index\n",
    "cutoff_values = list(range(5, 16))\n",
    "window_values = [i * res for i in range(2, 5)]\n",
    "for cutoff in cutoff_values:\n",
    "    for window in window_values:\n",
    "        for noise in noise_values:\n",
    "            for sim in sim_values:\n",
    "                print(f\"\\r sim={sim} noise={noise} window={window} cutoff={cutoff}\", end=\"\")\n",
    "                di = tad.directionality_index(matrices.loc[noise, sim], regions.loc[noise, sim], window_size=window)\n",
    "                tads = tad.call_tads_directionality_index(di, cutoff, regions=regions.loc[noise, sim])\n",
    "                with open(f\"{out_location}di_noise{noise}_sim{sim}_window{window}_cutoff{cutoff}.txt\", \"w\") as outfile:\n",
    "                    for some_tad in tads:\n",
    "                        outfile.write(f\"{some_tad.start - 1}\\t{some_tad.end}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
